@misc{liu2019robertarobustlyoptimizedbert,
      title={RoBERTa: A Robustly Optimized BERT Pretraining Approach}, 
      author={Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
      year={2019},
      eprint={1907.11692},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1907.11692}, 
}

@inproceedings{li2023blip,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  booktitle={International conference on machine learning},
  pages={19730--19742},
  year={2023},
  organization={PMLR}
}

@misc{vidgen2021,
      title={Learning from the Worst: Dynamically Generated Datasets to Improve Online Hate Detection}, 
      author={Bertie Vidgen and Tristan Thrush and Zeerak Waseem and Douwe Kiela},
      year={2021},
      eprint={2012.15761},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2012.15761}, 
}

@article{karagiannidis2007improved,
  title={An improved approximation for the Gaussian Q-function},
  author={Karagiannidis, George K and Lioumpas, Athanasios S},
  journal={IEEE Communications Letters},
  volume={11},
  number={8},
  pages={644--646},
  year={2007},
  publisher={IEEE}
}

@misc{ramesh2022hierarchicaltextconditionalimagegeneration,
      title={Hierarchical Text-Conditional Image Generation with CLIP Latents}, 
      author={Aditya Ramesh and Prafulla Dhariwal and Alex Nichol and Casey Chu and Mark Chen},
      year={2022},
      eprint={2204.06125},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2204.06125}, 
}

@article{zhang2023mutation,
  title={A mutation-based method for multi-modal jailbreaking attack detection},
  author={Zhang, Xiaoyu and Zhang, Cen and Li, Tianlin and Huang, Yihao and Jia, Xiaojun and Xie, Xiaofei and Liu, Yang and Shen, Chao},
  journal={arXiv preprint arXiv:2312.10766},
  year={2023}
}

@article{chang2011chernoff,
  title={Chernoff-type bounds for the Gaussian error function},
  author={Chang, Seok-Ho and Cosman, Pamela C and Milstein, Laurence B},
  journal={IEEE Transactions on Communications},
  volume={59},
  number={11},
  pages={2939--2944},
  year={2011},
  publisher={IEEE}
}

@article{chiani2003new,
  title={New exponential bounds and approximations for the computation of error probability in fading channels},
  author={Chiani, Marco and Dardari, Davide and Simon, Marvin K},
  journal={IEEE Transactions on Wireless Communications},
  volume={2},
  number={4},
  pages={840--845},
  year={2003},
  publisher={IEEE}
}

@article{liu2021self,
  title={Self-supervised learning: Generative or contrastive},
  author={Liu, Xiao and Zhang, Fanjin and Hou, Zhenyu and Mian, Li and Wang, Zhaoyu and Zhang, Jing and Tang, Jie},
  journal={IEEE transactions on knowledge and data engineering},
  volume={35},
  number={1},
  pages={857--876},
  year={2021},
  publisher={IEEE}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{lee2019tight,
  title={Tight certificates of adversarial robustness for randomly smoothed classifiers},
  author={Lee, Guang-He and Yuan, Yang and Chang, Shiyu and Jaakkola, Tommi},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@misc{huang2017safetyverificationdeepneural,
      title={Safety Verification of Deep Neural Networks}, 
      author={Xiaowei Huang and Marta Kwiatkowska and Sen Wang and Min Wu},
      year={2017},
      eprint={1610.06940},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/1610.06940}, 
}

@misc{alayrac2022flamingovisuallanguagemodel,
      title={Flamingo: a Visual Language Model for Few-Shot Learning}, 
      author={Jean-Baptiste Alayrac and Jeff Donahue and Pauline Luc and Antoine Miech and Iain Barr and Yana Hasson and Karel Lenc and Arthur Mensch and Katie Millican and Malcolm Reynolds and Roman Ring and Eliza Rutherford and Serkan Cabi and Tengda Han and Zhitao Gong and Sina Samangooei and Marianne Monteiro and Jacob Menick and Sebastian Borgeaud and Andrew Brock and Aida Nematzadeh and Sahand Sharifzadeh and Mikolaj Binkowski and Ricardo Barreira and Oriol Vinyals and Andrew Zisserman and Karen Simonyan},
      year={2022},
      eprint={2204.14198},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2204.14198}, 
}

@misc{jigsaw-toxic-comment-classification-challenge,
    author = {cjadams, Jeffrey Sorensen, Julia Elliott, Lucas Dixon, Mark McDonald, nithum, Will Cukierski},
    title = {Toxic Comment Classification Challenge},
    publisher = {Kaggle},
    year = {2017},
    url = {https://kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge}
}

@misc{ibrahim2024staticaievaluationsadvancing,
      title={Beyond static AI evaluations: advancing human interaction evaluations for LLM harms and risks}, 
      author={Lujain Ibrahim and Saffron Huang and Lama Ahmad and Markus Anderljung},
      year={2024},
      eprint={2405.10632},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      url={https://arxiv.org/abs/2405.10632}, 
}

@misc{lee2024evaluatinghumanlanguagemodelinteraction,
      title={Evaluating Human-Language Model Interaction}, 
      author={Mina Lee and Megha Srivastava and Amelia Hardy and John Thickstun and Esin Durmus and Ashwin Paranjape and Ines Gerard-Ursin and Xiang Lisa Li and Faisal Ladhak and Frieda Rong and Rose E. Wang and Minae Kwon and Joon Sung Park and Hancheng Cao and Tony Lee and Rishi Bommasani and Michael Bernstein and Percy Liang},
      year={2024},
      eprint={2212.09746},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2212.09746}, 
}

@misc{lecuyer2019certifiedrobustnessadversarialexamples,
      title={Certified Robustness to Adversarial Examples with Differential Privacy}, 
      author={Mathias Lecuyer and Vaggelis Atlidakis and Roxana Geambasu and Daniel Hsu and Suman Jana},
      year={2019},
      eprint={1802.03471},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1802.03471}, 
}

@misc{zeng2021certifieddefenselatentspace,
      title={Certified Defense via Latent Space Randomized Smoothing with Orthogonal Encoders}, 
      author={Huimin Zeng and Jiahao Su and Furong Huang},
      year={2021},
      eprint={2108.00491},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2108.00491}, 
}

@inproceedings{shayegani2023jailbreak,
  title={Jailbreak in pieces: Compositional adversarial attacks on multi-modal language models},
  author={Shayegani, Erfan and Dong, Yue and Abu-Ghazaleh, Nael},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@article{teng2020ell_1,
  title={L1 Adversarial Robustness Certificates: a Randomized Smoothing Approach},
  author={Teng, Jiaye and Lee, Guang-He and Yuan, Yang},
  year={2020}
}

@inproceedings{cao2017mitigating,
  title={Mitigating evasion attacks to deep neural networks via region-based classification},
  author={Cao, Xiaoyu and Gong, Neil Zhenqiang},
  booktitle={Proceedings of the 33rd Annual Computer Security Applications Conference},
  pages={278--287},
  year={2017}
}

@misc{chen2024dressinstructinglargevisionlanguage,
      title={DRESS: Instructing Large Vision-Language Models to Align and Interact with Humans via Natural Language Feedback}, 
      author={Yangyi Chen and Karan Sikka and Michael Cogswell and Heng Ji and Ajay Divakaran},
      year={2024},
      eprint={2311.10081},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2311.10081}, 
}

@article{salman2020denoised,
  title={Denoised smoothing: A provable defense for pretrained classifiers},
  author={Salman, Hadi and Sun, Mingjie and Yang, Greg and Kapoor, Ashish and Kolter, J Zico},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={21945--21957},
  year={2020}
}

@misc{dwork2011fairnessawareness,
      title={Fairness Through Awareness}, 
      author={Cynthia Dwork and Moritz Hardt and Toniann Pitassi and Omer Reingold and Rich Zemel},
      year={2011},
      eprint={1104.3913},
      archivePrefix={arXiv},
      primaryClass={cs.CC},
      url={https://arxiv.org/abs/1104.3913}, 
}


@inproceedings{luo2023image,
  title={An image is worth 1000 lies: Transferability of adversarial images across prompts on vision-language models},
  author={Luo, Haochen and Gu, Jindong and Liu, Fengyuan and Torr, Philip},
  booktitle={The Twelfth International Conference on Learning Representations}
}

@article{tao2024imgtrojan,
  title={ImgTrojan: Jailbreaking Vision-Language Models with ONE Image},
  author={Tao, Xijia and Zhong, Shuai and Li, Lei and Liu, Qi and Kong, Lingpeng},
  journal={arXiv preprint arXiv:2403.02910},
  year={2024}
}

@article{van_Erven_2014,
   title={Rényi Divergence and Kullback-Leibler Divergence},
   volume={60},
   ISSN={1557-9654},
   url={http://dx.doi.org/10.1109/TIT.2014.2320500},
   DOI={10.1109/tit.2014.2320500},
   number={7},
   journal={IEEE Transactions on Information Theory},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={van Erven, Tim and Harremoes, Peter},
   year={2014},
   month=jul, pages={3797–3820} }

@inproceedings{liu2018towards,
  title={Towards robust neural networks via random self-ensemble},
  author={Liu, Xuanqing and Cheng, Minhao and Zhang, Huan and Hsieh, Cho-Jui},
  booktitle={Proceedings of the european conference on computer vision (ECCV)},
  pages={369--385},
  year={2018}
}

@misc{gong2023figstepjailbreakinglargevisionlanguage,
      title={FigStep: Jailbreaking Large Vision-language Models via Typographic Visual Prompts}, 
      author={Yichen Gong and Delong Ran and Jinyuan Liu and Conglei Wang and Tianshuo Cong and Anyu Wang and Sisi Duan and Xiaoyun Wang},
      year={2023},
      eprint={2311.05608},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2311.05608}, 
}

@inproceedings{logacheva-etal-2022-paradetox,
    title = "{P}ara{D}etox: Detoxification with Parallel Data",
    author = "Logacheva, Varvara  and
      Dementieva, Daryna  and
      Ustyantsev, Sergey  and
      Moskovskiy, Daniil  and
      Dale, David  and
      Krotova, Irina  and
      Semenov, Nikita  and
      Panchenko, Alexander",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.469",
    pages = "6804--6818",
    abstract = "We present a novel pipeline for the collection of parallel data for the detoxification task. We collect non-toxic paraphrases for over 10,000 English toxic sentences. We also show that this pipeline can be used to distill a large existing corpus of paraphrases to get toxic-neutral sentence pairs. We release two parallel corpora which can be used for the training of detoxification models. To the best of our knowledge, these are the first parallel datasets for this task.We describe our pipeline in detail to make it fast to set up for a new language or domain, thus contributing to faster and easier development of new parallel resources.We train several detoxification models on the collected data and compare them with several baselines and state-of-the-art unsupervised approaches. We conduct both automatic and manual evaluations. All models trained on parallel data outperform the state-of-the-art unsupervised models by a large margin. This suggests that our novel datasets can boost the performance of detoxification systems.",
}


@article{zhao2024evaluating,
  title={On evaluating adversarial robustness of large vision-language models},
  author={Zhao, Yunqing and Pang, Tianyu and Du, Chao and Yang, Xiao and Li, Chongxuan and Cheung, Ngai-Man Man and Lin, Min},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{gou2024eyes,
  title={Eyes closed, safety on: Protecting multimodal llms via image-to-text transformation},
  author={Gou, Yunhao and Chen, Kai and Liu, Zhili and Hong, Lanqing and Xu, Hang and Li, Zhenguo and Yeung, Dit-Yan and Kwok, James T and Zhang, Yu},
  journal={arXiv preprint arXiv:2403.09572},
  year={2024}
}

@misc{gouk2020regularisationneuralnetworksenforcing,
      title={Regularisation of Neural Networks by Enforcing Lipschitz Continuity}, 
      author={Henry Gouk and Eibe Frank and Bernhard Pfahringer and Michael J. Cree},
      year={2020},
      eprint={1804.04368},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1804.04368}, 
}

@article{ying2024jailbreak,
  title={Jailbreak Vision Language Models via Bi-Modal Adversarial Prompt},
  author={Ying, Zonghao and Liu, Aishan and Zhang, Tianyuan and Yu, Zhengmin and Liang, Siyuan and Liu, Xianglong and Tao, Dacheng},
  journal={arXiv preprint arXiv:2406.04031},
  year={2024}
}

@misc{liu2024mmsafetybenchbenchmarksafetyevaluation,
      title={MM-SafetyBench: A Benchmark for Safety Evaluation of Multimodal Large Language Models}, 
      author={Xin Liu and Yichen Zhu and Jindong Gu and Yunshi Lan and Chao Yang and Yu Qiao},
      year={2024},
      eprint={2311.17600},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2311.17600}, 
}

@misc{li2023blip2bootstrappinglanguageimagepretraining,
      title={BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models}, 
      author={Junnan Li and Dongxu Li and Silvio Savarese and Steven Hoi},
      year={2023},
      eprint={2301.12597},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2301.12597}, 
}

@inproceedings{individual-fairness,
author = {Fleisher, Will},
title = {What's Fair about Individual Fairness?},
year = {2021},
isbn = {9781450384735},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461702.3462621},
doi = {10.1145/3461702.3462621},
abstract = {One of the main lines of research in algorithmic fairness involves individual fairness (IF) methods. Individual fairness is motivated by an intuitive principle, similar treatment, which requires that similar individuals be treated similarly. IF offers a precise account of this principle using distance metrics to evaluate the similarity of individuals. Proponents of individual fairness have argued that it gives the correct definition of algorithmic fairness, and that it should therefore be preferred to other methods for determining fairness. I argue that individual fairness cannot serve as a definition of fairness. Moreover, IF methods should not be given priority over other fairness methods, nor used in isolation from them. To support these conclusions, I describe four in-principle problems for individual fairness as a definition and as a method for ensuring fairness: (1) counterexamples show that similar treatment (and therefore IF) are insufficient to guarantee fairness; (2) IF methods for learning similarity metrics are at risk of encoding human implicit bias; (3) IF requires prior moral judgments, limiting its usefulness as a guide for fairness and undermining its claim to define fairness; and (4) the incommensurability of relevant moral values makes similarity metrics impossible for many tasks. In light of these limitations, I suggest that individual fairness cannot be a definition of fairness, and instead should be seen as one tool among several for ameliorating algorithmic bias.},
booktitle = {Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {480–490},
numpages = {11},
keywords = {algorithmic fairness, ethics of AI, incommensurable values, individual fairness},
location = {Virtual Event, USA},
series = {AIES '21}
}

@article{wang2024adashield,
  title={Adashield: Safeguarding multimodal large language models from structure-based attack via adaptive shield prompting},
  author={Wang, Yu and Liu, Xiaogeng and Li, Yu and Chen, Muhao and Xiao, Chaowei},
  journal={arXiv preprint arXiv:2403.09513},
  year={2024}
}

@misc{hein2017formalguaranteesrobustnessclassifier,
      title={Formal Guarantees on the Robustness of a Classifier against Adversarial Manipulation}, 
      author={Matthias Hein and Maksym Andriushchenko},
      year={2017},
      eprint={1705.08475},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1705.08475}, 
}

@inproceedings{qi2024visual,
  title={Visual adversarial examples jailbreak aligned large language models},
  author={Qi, Xiangyu and Huang, Kaixuan and Panda, Ashwinee and Henderson, Peter and Wang, Mengdi and Mittal, Prateek},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={19},
  pages={21527--21536},
  year={2024}
}

@article{zhang2020filling,
  title={Filling the soap bubbles: Efficient black-box adversarial certification with non-gaussian smoothing},
  author={Zhang, Dinghuai and Ye, Mao and Gong, Chengyue and Zhu, Zhanxing and Liu, Qiang},
  year={2020}
}

@misc{yang2020randomizedsmoothingshapessizes,
      title={Randomized Smoothing of All Shapes and Sizes}, 
      author={Greg Yang and Tony Duan and J. Edward Hu and Hadi Salman and Ilya Razenshteyn and Jerry Li},
      year={2020},
      eprint={2002.08118},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2002.08118}, 
}

@misc{wong2018provabledefensesadversarialexamples,
      title={Provable defenses against adversarial examples via the convex outer adversarial polytope}, 
      author={Eric Wong and J. Zico Kolter},
      year={2018},
      eprint={1711.00851},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1711.00851}, 
}

@article{Rusek_2020,
   title={RouteNet: Leveraging Graph Neural Networks for Network Modeling and Optimization in SDN},
   volume={38},
   ISSN={1558-0008},
   url={http://dx.doi.org/10.1109/JSAC.2020.3000405},
   DOI={10.1109/jsac.2020.3000405},
   number={10},
   journal={IEEE Journal on Selected Areas in Communications},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Rusek, Krzysztof and Suarez-Varela, Jose and Almasan, Paul and Barlet-Ros, Pere and Cabellos-Aparicio, Albert},
   year={2020},
   month=oct, pages={2260–2270} }

@article{pi2024mllm,
  title={MLLM-Protector: Ensuring MLLM's Safety without Hurting Performance},
  author={Pi, Renjie and Han, Tianyang and Xie, Yueqi and Pan, Rui and Lian, Qing and Dong, Hanze and Zhang, Jipeng and Zhang, Tong},
  journal={arXiv preprint arXiv:2401.02906},
  year={2024}
}

@article{liu2023autodan,
  title={Autodan: Generating stealthy jailbreak prompts on aligned large language models},
  author={Liu, Xiaogeng and Xu, Nan and Chen, Muhao and Xiao, Chaowei},
  journal={arXiv preprint arXiv:2310.04451},
  year={2023}
}

@article{zhang2020gnnguard,
  title={Gnnguard: Defending graph neural networks against adversarial attacks},
  author={Zhang, Xiang and Zitnik, Marinka},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={9263--9275},
  year={2020}
}

@misc{cohen2019certifiedadversarialrobustnessrandomized,
      title={Certified Adversarial Robustness via Randomized Smoothing}, 
      author={Jeremy M Cohen and Elan Rosenfeld and J. Zico Kolter},
      year={2019},
      eprint={1902.02918},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1902.02918}, 
}

@article{niu2024jailbreaking,
  title={Jailbreaking attack against multimodal large language model},
  author={Niu, Zhenxing and Ren, Haodong and Gao, Xinbo and Hua, Gang and Jin, Rong},
  journal={arXiv preprint arXiv:2402.02309},
  year={2024}
}

@article{jaiswal2020survey,
  title={A survey on contrastive self-supervised learning},
  author={Jaiswal, Ashish and Babu, Ashwin Ramesh and Zadeh, Mohammad Zaki and Banerjee, Debapriya and Makedon, Fillia},
  journal={Technologies},
  volume={9},
  number={1},
  pages={2},
  year={2020},
  publisher={MDPI}
}

@article{li2019certified,
  title={Certified adversarial robustness with additive noise},
  author={Li, Bai and Chen, Changyou and Wang, Wenlin and Carin, Lawrence},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@misc{tsimpoukelli2021multimodalfewshotlearningfrozen,
      title={Multimodal Few-Shot Learning with Frozen Language Models}, 
      author={Maria Tsimpoukelli and Jacob Menick and Serkan Cabi and S. M. Ali Eslami and Oriol Vinyals and Felix Hill},
      year={2021},
      eprint={2106.13884},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2106.13884}, 
}

@inproceedings{kumar2020curse,
  title={Curse of dimensionality on randomized smoothing for certifiable robustness},
  author={Kumar, Aounon and Levine, Alexander and Goldstein, Tom and Feizi, Soheil},
  booktitle={International Conference on Machine Learning},
  pages={5458--5467},
  year={2020},
  organization={PMLR}
}

@article{zugner2020adversarial,
  title={Adversarial attacks on graph neural networks: Perturbations and their patterns},
  author={Z{\"u}gner, Daniel and Borchert, Oliver and Akbarnejad, Amir and G{\"u}nnemann, Stephan},
  journal={ACM Transactions on Knowledge Discovery from Data (TKDD)},
  volume={14},
  number={5},
  pages={1--31},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@article{neyman1933ix,
  title={IX. On the problem of the most efficient tests of statistical hypotheses},
  author={Neyman, Jerzy and Pearson, Egon Sharpe},
  journal={Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character},
  volume={231},
  number={694-706},
  pages={289--337},
  year={1933},
  publisher={The Royal Society London}
}

@misc{katz2017reluplexefficientsmtsolver,
      title={Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks}, 
      author={Guy Katz and Clark Barrett and David Dill and Kyle Julian and Mykel Kochenderfer},
      year={2017},
      eprint={1702.01135},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/1702.01135}, 
}

@ARTICLE{9226466,
  author={Le-Khac, Phuc H. and Healy, Graham and Smeaton, Alan F.},
  journal={IEEE Access}, 
  title={Contrastive Representation Learning: A Framework and Review}, 
  year={2020},
  volume={8},
  number={},
  pages={193907-193934},
  keywords={Task analysis;Feature extraction;Computational modeling;Data models;Machine learning;Learning systems;Natural language processing;Contrastive learning;representation learning;self-supervised learning;unsupervised learning;deep learning;machine learning},
  doi={10.1109/ACCESS.2020.3031549}}

@misc{pi2024mllmprotectorensuringmllmssafety,
      title={MLLM-Protector: Ensuring MLLM's Safety without Hurting Performance}, 
      author={Renjie Pi and Tianyang Han and Jianshu Zhang and Yueqi Xie and Rui Pan and Qing Lian and Hanze Dong and Jipeng Zhang and Tong Zhang},
      year={2024},
      eprint={2401.02906},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2401.02906}, 
}

@misc{nichol2022glidephotorealisticimagegeneration,
      title={GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models}, 
      author={Alex Nichol and Prafulla Dhariwal and Aditya Ramesh and Pranav Shyam and Pamela Mishkin and Bob McGrew and Ilya Sutskever and Mark Chen},
      year={2022},
      eprint={2112.10741},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2112.10741}, 
}

@misc{cheng2017maximumresilienceartificialneural,
      title={Maximum Resilience of Artificial Neural Networks}, 
      author={Chih-Hong Cheng and Georg Nührenberg and Harald Ruess},
      year={2017},
      eprint={1705.01040},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1705.01040}, 
}

@misc{radford2021learningtransferablevisualmodels,
      title={Learning Transferable Visual Models From Natural Language Supervision}, 
      author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
      year={2021},
      eprint={2103.00020},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2103.00020}, 
}

@inproceedings{yang2022vision,
  title={Vision-language pre-training with triple contrastive learning},
  author={Yang, Jinyu and Duan, Jiali and Tran, Son and Xu, Yi and Chanda, Sampath and Chen, Liqun and Zeng, Belinda and Chilimbi, Trishul and Huang, Junzhou},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15671--15680},
  year={2022}
}

@article{gunel2020supervised,
  title={Supervised contrastive learning for pre-trained language model fine-tuning},
  author={Gunel, Beliz and Du, Jingfei and Conneau, Alexis and Stoyanov, Ves},
  journal={arXiv preprint arXiv:2011.01403},
  year={2020}
}

@article{yu2020fine,
  title={Fine-tuning pre-trained language model with weak supervision: A contrastive-regularized self-training approach},
  author={Yu, Yue and Zuo, Simiao and Jiang, Haoming and Ren, Wendi and Zhao, Tuo and Zhang, Chao},
  journal={arXiv preprint arXiv:2010.07835},
  year={2020}
}

@misc{wicker2023certificationdistributionalindividualfairness,
      title={Certification of Distributional Individual Fairness}, 
      author={Matthew Wicker and Vihari Piratia and Adrian Weller},
      year={2023},
      eprint={2311.11911},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2311.11911}, 
}

@misc{gou2024eyesclosedsafetyon,
      title={Eyes Closed, Safety On: Protecting Multimodal LLMs via Image-to-Text Transformation}, 
      author={Yunhao Gou and Kai Chen and Zhili Liu and Lanqing Hong and Hang Xu and Zhenguo Li and Dit-Yan Yeung and James T. Kwok and Yu Zhang},
      year={2024},
      eprint={2403.09572},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2403.09572}, 
}
